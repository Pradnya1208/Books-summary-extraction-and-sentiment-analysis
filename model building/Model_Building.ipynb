{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pradnya1208/Books-summary-extraction-and-sentiment-analysis/blob/main/model%20building/Model_Building.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9be6062f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9be6062f",
        "outputId": "5a60b27c-2587-41e1-debd-5c69529ff37f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-27 13:57:49--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-03-27 13:57:49--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-03-27 13:57:49--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.05MB/s    in 2m 40s  \n",
            "\n",
            "2022-03-27 14:00:29 (5.15 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import requests\n",
        "\n",
        "import string\n",
        "from collections import Counter\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ngyNmBvwPZQ",
        "outputId": "66619032-0a0a-4bb8-d2e6-7c8656aa5bff"
      },
      "id": "-ngyNmBvwPZQ",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-27 14:21:50--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.88.13\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.88.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  45.2MB/s    in 35s     \n",
            "\n",
            "2022-03-27 14:22:26 (44.5 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "70db0029",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70db0029",
        "outputId": "71d2afd9-180d-4821-97aa-2e345a3ef66d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Tensorflow Version 2.8.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import nltk \n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "import re\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dropout\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "from bs4 import BeautifulSoup\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "#import cufflinks\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "import plotly.figure_factory as ff\n",
        "InteractiveShell.ast_node_interactivity = 'all'\n",
        "\n",
        "print(\"Tensorflow Version\",tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a4e95204",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "a4e95204",
        "outputId": "c6b617fb-b082-4646-8449-8050302b4327"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       title  \\\n",
              "0                           The Hunger Games   \n",
              "1  Harry Potter and the Order of the Phoenix   \n",
              "2                      To Kill a Mockingbird   \n",
              "3                        Pride and Prejudice   \n",
              "4                             The Book Thief   \n",
              "\n",
              "                                             summary  anger  anticipation  \\\n",
              "0  Could you survive on your own in the wild, wit...      8             8   \n",
              "1  There is a door at the end of a silent corrido...     14             7   \n",
              "2  The unforgettable novel of a childhood in a sl...      2             4   \n",
              "3  Alternate cover edition of ISBN 9780679783268S...      5            15   \n",
              "4  Librarian's note: An alternate cover edition c...      3             5   \n",
              "\n",
              "   disgust  fear  joy  negative  positive  sadness  surprise  trust  \\\n",
              "0       10     9    6        16        11       11         5      5   \n",
              "1        5    15    6        18        18       13         5     10   \n",
              "2        2     5    8         8        15        5         1      2   \n",
              "3        2     3   22         8        26        0         3     15   \n",
              "4        3     7    3         9        11        4         4     11   \n",
              "\n",
              "  sentiment_class  \n",
              "0        Negative  \n",
              "1         Neutral  \n",
              "2        Positive  \n",
              "3        Positive  \n",
              "4        Positive  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dbdd320d-4fb2-4134-8535-ddba24a5ed9b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>summary</th>\n",
              "      <th>anger</th>\n",
              "      <th>anticipation</th>\n",
              "      <th>disgust</th>\n",
              "      <th>fear</th>\n",
              "      <th>joy</th>\n",
              "      <th>negative</th>\n",
              "      <th>positive</th>\n",
              "      <th>sadness</th>\n",
              "      <th>surprise</th>\n",
              "      <th>trust</th>\n",
              "      <th>sentiment_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Hunger Games</td>\n",
              "      <td>Could you survive on your own in the wild, wit...</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>16</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Harry Potter and the Order of the Phoenix</td>\n",
              "      <td>There is a door at the end of a silent corrido...</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>15</td>\n",
              "      <td>6</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>To Kill a Mockingbird</td>\n",
              "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pride and Prejudice</td>\n",
              "      <td>Alternate cover edition of ISBN 9780679783268S...</td>\n",
              "      <td>5</td>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>22</td>\n",
              "      <td>8</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Book Thief</td>\n",
              "      <td>Librarian's note: An alternate cover edition c...</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dbdd320d-4fb2-4134-8535-ddba24a5ed9b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dbdd320d-4fb2-4134-8535-ddba24a5ed9b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dbdd320d-4fb2-4134-8535-ddba24a5ed9b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "model_data = pd.read_csv(\"/content/model_data.csv\")\n",
        "model_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "743d35c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "743d35c6",
        "outputId": "60c8e8f3-9cb4-4958-bcb9-d062f3f42b13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             anger  anticipation      disgust         fear          joy  \\\n",
              "count  1084.000000   1084.000000  1084.000000  1084.000000  1084.000000   \n",
              "mean      4.802583      7.273063     3.440037     7.455720     6.680812   \n",
              "std       4.180568      4.835920     3.160102     5.472577     4.949567   \n",
              "min       0.000000      0.000000     0.000000     0.000000     0.000000   \n",
              "25%       2.000000      4.000000     1.000000     3.000000     3.000000   \n",
              "50%       4.000000      7.000000     3.000000     6.000000     6.000000   \n",
              "75%       7.000000     10.000000     5.000000    11.000000     9.000000   \n",
              "max      25.000000     46.000000    21.000000    31.000000    35.000000   \n",
              "\n",
              "          negative     positive      sadness     surprise        trust  \n",
              "count  1084.000000  1084.000000  1084.000000  1084.000000  1084.000000  \n",
              "mean     10.226937    15.158672     5.087638     3.691882     8.296125  \n",
              "std       6.611929     8.652238     4.011373     2.938126     5.396379  \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
              "25%       5.000000     9.000000     2.000000     2.000000     4.000000  \n",
              "50%       9.000000    14.000000     4.000000     3.000000     8.000000  \n",
              "75%      14.000000    20.000000     7.000000     5.000000    11.000000  \n",
              "max      39.000000    86.000000    25.000000    20.000000    58.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-033d2bc1-4ed7-4ec7-a612-3f21889ea20e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>anger</th>\n",
              "      <th>anticipation</th>\n",
              "      <th>disgust</th>\n",
              "      <th>fear</th>\n",
              "      <th>joy</th>\n",
              "      <th>negative</th>\n",
              "      <th>positive</th>\n",
              "      <th>sadness</th>\n",
              "      <th>surprise</th>\n",
              "      <th>trust</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1084.000000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>1084.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.802583</td>\n",
              "      <td>7.273063</td>\n",
              "      <td>3.440037</td>\n",
              "      <td>7.455720</td>\n",
              "      <td>6.680812</td>\n",
              "      <td>10.226937</td>\n",
              "      <td>15.158672</td>\n",
              "      <td>5.087638</td>\n",
              "      <td>3.691882</td>\n",
              "      <td>8.296125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.180568</td>\n",
              "      <td>4.835920</td>\n",
              "      <td>3.160102</td>\n",
              "      <td>5.472577</td>\n",
              "      <td>4.949567</td>\n",
              "      <td>6.611929</td>\n",
              "      <td>8.652238</td>\n",
              "      <td>4.011373</td>\n",
              "      <td>2.938126</td>\n",
              "      <td>5.396379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>11.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>25.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>58.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-033d2bc1-4ed7-4ec7-a612-3f21889ea20e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-033d2bc1-4ed7-4ec7-a612-3f21889ea20e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-033d2bc1-4ed7-4ec7-a612-3f21889ea20e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "model_data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f99fe998",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "f99fe998",
        "outputId": "259aa9d4-acbc-44d1-e31b-b62c1f6f2eb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f72f43e8e50>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "sns.countplot(x = 'sentiment_class', data = model_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01770c3a",
      "metadata": {
        "id": "01770c3a"
      },
      "source": [
        "Our data is imbalanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "979e2e7b",
      "metadata": {
        "id": "979e2e7b"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "df_summary = model_data[[\"title\",\"summary\", \"sentiment_class\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiclass text classification"
      ],
      "metadata": {
        "id": "Gzr97hy3s_xs"
      },
      "id": "Gzr97hy3s_xs"
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "import gensim\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "rn--d5n1tCZP"
      },
      "id": "rn--d5n1tCZP",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes Classifier for Multinomial Models"
      ],
      "metadata": {
        "id": "prjQT8ywu80z"
      },
      "id": "prjQT8ywu80z"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "X = df_summary.summary\n",
        "y = df_summary.sentiment_class\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)\n",
        "\n",
        "\n",
        "\n",
        "nb = Pipeline([('vect', CountVectorizer()),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('clf', MultinomialNB()),\n",
        "              ])\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = nb.predict(X_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=[\"Positive\", \"Negative\", \"Neutral\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zh1imi2_tDvy",
        "outputId": "cbc3c5eb-4ce0-4c58-8897-65c7ab881128"
      },
      "id": "Zh1imi2_tDvy",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
              "                ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.6748466257668712\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.00      0.00      0.00        96\n",
            "    Negative       0.00      0.00      0.00        10\n",
            "     Neutral       0.67      1.00      0.81       220\n",
            "\n",
            "    accuracy                           0.67       326\n",
            "   macro avg       0.22      0.33      0.27       326\n",
            "weighted avg       0.46      0.67      0.54       326\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_tags = [\"Positive\", \"Negative\", \"Neutral\"]"
      ],
      "metadata": {
        "id": "ygHnquF4uqFw"
      },
      "id": "ygHnquF4uqFw",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Support Vector Machine"
      ],
      "metadata": {
        "id": "g0eJSFYmvJNK"
      },
      "id": "g0eJSFYmvJNK"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
        "               ])\n",
        "sgd.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = sgd.predict(X_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=my_tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9wnHPy5th7U",
        "outputId": "3112b3b2-c2a4-427b-d08a-c16184380a1a"
      },
      "id": "o9wnHPy5th7U",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
              "                ('clf',\n",
              "                 SGDClassifier(alpha=0.001, max_iter=5, random_state=42,\n",
              "                               tol=None))])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.7239263803680982\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.74      0.26      0.38        96\n",
            "    Negative       0.00      0.00      0.00        10\n",
            "     Neutral       0.72      0.96      0.82       220\n",
            "\n",
            "    accuracy                           0.72       326\n",
            "   macro avg       0.49      0.41      0.40       326\n",
            "weighted avg       0.70      0.72      0.67       326\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "auKPsXtVvPfD"
      },
      "id": "auKPsXtVvPfD"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
        "               ])\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=my_tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cbGfA4huuCT",
        "outputId": "c4f99493-7098-4894-be35-c418b8a41410"
      },
      "id": "6cbGfA4huuCT",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
              "                ('clf', LogisticRegression(C=100000.0, n_jobs=1))])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.7331288343558282\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.71      0.31      0.43        96\n",
            "    Negative       0.00      0.00      0.00        10\n",
            "     Neutral       0.74      0.95      0.83       220\n",
            "\n",
            "    accuracy                           0.73       326\n",
            "   macro avg       0.48      0.42      0.42       326\n",
            "weighted avg       0.71      0.73      0.69       326\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2vec and Logistic Regression"
      ],
      "metadata": {
        "id": "QZv4d-XZvxIa"
      },
      "id": "QZv4d-XZvxIa"
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "wv = gensim.models.KeyedVectors.load_word2vec_format(\"/content/GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
        "wv.init_sims(replace=True)"
      ],
      "metadata": {
        "id": "UvXBYrpPvTpJ"
      },
      "id": "UvXBYrpPvTpJ",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def word_averaging(wv, words):\n",
        "    all_words, mean = set(), []\n",
        "    \n",
        "    for word in words:\n",
        "        if isinstance(word, np.ndarray):\n",
        "            mean.append(word)\n",
        "        elif word in wv.vocab:\n",
        "            mean.append(wv.syn0norm[wv.vocab[word].index])\n",
        "            all_words.add(wv.vocab[word].index)\n",
        "\n",
        "    if not mean:\n",
        "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
        "        # FIXME: remove these examples in pre-processing\n",
        "        return np.zeros(wv.vector_size,)\n",
        "\n",
        "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
        "    return mean\n",
        "\n",
        "def  word_averaging_list(wv, text_list):\n",
        "    return np.vstack([word_averaging(wv, post) for post in text_list ])"
      ],
      "metadata": {
        "id": "4wlESuU8v0uo"
      },
      "id": "4wlESuU8v0uo",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erOqeCmyyRay",
        "outputId": "93de0549-34d0-4b5c-b05b-097412f82e09"
      },
      "id": "erOqeCmyyRay",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def w2v_tokenize_text(text):\n",
        "    tokens = []\n",
        "    for sent in nltk.sent_tokenize(text, language='english'):\n",
        "        for word in nltk.word_tokenize(sent, language='english'):\n",
        "            if len(word) < 2:\n",
        "                continue\n",
        "            tokens.append(word)\n",
        "    return tokens\n",
        "    \n",
        "train, test = train_test_split(df_summary, test_size=0.3, random_state = 42)\n",
        "\n",
        "test_tokenized = test.apply(lambda r: w2v_tokenize_text(r['summary']), axis=1).values\n",
        "train_tokenized = train.apply(lambda r: w2v_tokenize_text(r['summary']), axis=1).values\n",
        "\n",
        "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
        "X_test_word_average = word_averaging_list(wv,test_tokenized)"
      ],
      "metadata": {
        "id": "M_e2jSUnx-DL"
      },
      "id": "M_e2jSUnx-DL",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
        "logreg = logreg.fit(X_train_word_average, train['sentiment_class'])\n",
        "y_pred = logreg.predict(X_test_word_average)\n",
        "print('accuracy %s' % accuracy_score(y_pred, test.sentiment_class))\n",
        "print(classification_report(test.sentiment_class, y_pred,target_names=my_tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0inDb_pyCoS",
        "outputId": "f77c0341-eaa4-4172-9edd-43600d06adaa"
      },
      "id": "s0inDb_pyCoS",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.7239263803680982\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.60      0.58      0.59        96\n",
            "    Negative       0.00      0.00      0.00        10\n",
            "     Neutral       0.82      0.82      0.82       220\n",
            "\n",
            "    accuracy                           0.72       326\n",
            "   macro avg       0.47      0.47      0.47       326\n",
            "weighted avg       0.73      0.72      0.73       326\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Doc2vec and Logistic Regression"
      ],
      "metadata": {
        "id": "so03rYZSyozF"
      },
      "id": "so03rYZSyozF"
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "tqdm.pandas(desc=\"progress-bar\")\n",
        "from gensim.models import Doc2Vec\n",
        "from sklearn import utils\n",
        "import gensim\n",
        "#from gensim.models.doc2vec import TaggedDocument\n",
        "import re\n",
        "\n",
        "from gensim.models import Doc2Vec\n",
        "import gensim\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "\n",
        "def label_sentences(corpus, label_type):\n",
        "    \"\"\"\n",
        "    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
        "    We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
        "    a dummy index of the post.\n",
        "    \"\"\"\n",
        "    labeled = []\n",
        "    for i, v in enumerate(corpus):\n",
        "        label = label_type + '_' + str(i)\n",
        "        labeled.append(TaggedDocument(v.split(), [label]))\n",
        "    return labeled\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_summary.summary, df_summary.sentiment_class, random_state=0, test_size=0.3)\n",
        "X_train = label_sentences(X_train, 'Train')\n",
        "X_test = label_sentences(X_test, 'Test')\n",
        "all_data = X_train + X_test"
      ],
      "metadata": {
        "id": "eLOgr7YIyXaS"
      },
      "id": "eLOgr7YIyXaS",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
        "model_dbow.build_vocab([x for x in tqdm(all_data)])\n",
        "\n",
        "for epoch in range(30):\n",
        "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n",
        "    model_dbow.alpha -= 0.002\n",
        "    model_dbow.min_alpha = model_dbow.alpha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dExYtcyysrq",
        "outputId": "1a78b1bb-0020-456a-fb8a-173b3c610825"
      },
      "id": "0dExYtcyysrq",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1084/1084 [00:00<00:00, 906966.99it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 700342.81it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 284217.39it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 324457.68it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 1062792.32it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 1214376.48it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 1149298.67it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 1800643.78it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 254271.32it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 1810683.21it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 1144092.99it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 1848221.76it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 232837.89it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 1071306.68it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 743398.55it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 535969.06it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 1226166.54it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 1168798.34it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 1924090.37it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 1931446.70it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 1168197.72it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 1172717.45it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 1185251.70it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 1180328.54it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 1950504.31it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 1214052.21it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 1133821.83it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 1970795.64it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 1915175.04it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 736414.89it/s]\n",
            "100%|██████████| 1084/1084 [00:00<00:00, 1182785.00it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
        "    \"\"\"\n",
        "    Get vectors from trained doc2vec model\n",
        "    :param doc2vec_model: Trained Doc2Vec model\n",
        "    :param corpus_size: Size of the data\n",
        "    :param vectors_size: Size of the embedding vectors\n",
        "    :param vectors_type: Training or Testing vectors\n",
        "    :return: list of vectors\n",
        "    \"\"\"\n",
        "    vectors = np.zeros((corpus_size, vectors_size))\n",
        "    for i in range(0, corpus_size):\n",
        "        prefix = vectors_type + '_' + str(i)\n",
        "        vectors[i] = model.docvecs[prefix]\n",
        "    return vectors\n",
        "    \n",
        "train_vectors_dbow = get_vectors(model_dbow, len(X_train), 300, 'Train')\n",
        "test_vectors_dbow = get_vectors(model_dbow, len(X_test), 300, 'Test')"
      ],
      "metadata": {
        "id": "Qx1w2axszMCq"
      },
      "id": "Qx1w2axszMCq",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
        "logreg.fit(train_vectors_dbow, y_train)\n",
        "logreg = logreg.fit(train_vectors_dbow, y_train)\n",
        "y_pred = logreg.predict(test_vectors_dbow)\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=my_tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TXu3JoGzfmy",
        "outputId": "41ec4473-5749-490c-909f-9971f639827c"
      },
      "id": "5TXu3JoGzfmy",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=100000.0, n_jobs=1)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.6809815950920245\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.57      0.53      0.55        92\n",
            "    Negative       0.05      0.07      0.06        15\n",
            "     Neutral       0.79      0.79      0.79       219\n",
            "\n",
            "    accuracy                           0.68       326\n",
            "   macro avg       0.47      0.46      0.46       326\n",
            "weighted avg       0.69      0.68      0.69       326\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep learning"
      ],
      "metadata": {
        "id": "V7Az90Eqzskm"
      },
      "id": "V7Az90Eqzskm"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import itertools\n",
        "import os\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import utils\n",
        "\n",
        "train_size = int(len(df_summary) * .7)\n",
        "train_posts = df_summary['summary'][:train_size]\n",
        "train_tags = df_summary['sentiment_class'][:train_size]\n",
        "\n",
        "test_posts = df_summary['summary'][train_size:]\n",
        "test_tags = df_summary['sentiment_class'][train_size:]\n",
        "\n",
        "max_words = 15000\n",
        "tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
        "tokenize.fit_on_texts(train_posts) # only fit on train\n",
        "\n",
        "x_train = tokenize.texts_to_matrix(train_posts)\n",
        "x_test = tokenize.texts_to_matrix(test_posts)\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(train_tags)\n",
        "y_train = encoder.transform(train_tags)\n",
        "y_test = encoder.transform(test_tags)\n",
        "\n",
        "num_classes = np.max(y_train) + 1\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EIj-ze0zjUv",
        "outputId": "90362ae8-350e-45ab-fc0c-0c0e49caae43"
      },
      "id": "6EIj-ze0zjUv",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_shape=(max_words,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNAIxdjY0cAE",
        "outputId": "88e5fb23-6ef4-4e60-caf5-154f9378d53d"
      },
      "id": "lNAIxdjY0cAE",
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "22/22 [==============================] - 3s 108ms/step - loss: 0.7807 - accuracy: 0.6848 - val_loss: 0.6965 - val_accuracy: 0.6711\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.3244 - accuracy: 0.9282 - val_loss: 0.6900 - val_accuracy: 0.7105\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 1s 61ms/step - loss: 0.1276 - accuracy: 0.9677 - val_loss: 0.7257 - val_accuracy: 0.7368\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.0467 - accuracy: 0.9985 - val_loss: 0.7872 - val_accuracy: 0.7368\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 1s 54ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.8534 - val_accuracy: 0.7237\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 1s 59ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.8843 - val_accuracy: 0.7237\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 1s 62ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.9093 - val_accuracy: 0.7368\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 1s 56ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.9295 - val_accuracy: 0.7368\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 1s 62ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.9477 - val_accuracy: 0.7368\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 1s 54ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9634 - val_accuracy: 0.7368\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test,\n",
        "                       batch_size=batch_size, verbose=1)\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR18uTZO0WsP",
        "outputId": "9a0d4817-4117-41d9-ae7e-a8d747be193e"
      },
      "id": "pR18uTZO0WsP",
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 0s 18ms/step - loss: 1.0118 - accuracy: 0.7147\n",
            "Test accuracy: 0.7147239446640015\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Model Building.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}